#!/usr/bin/env python3
"""
è°ƒè¯•ä¸¢å¤±çš„å†…å®¹
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from contract_splitter.docx_splitter import DocxSplitter


def debug_missing_content():
    """è°ƒè¯•ä¸¢å¤±çš„å†…å®¹"""
    print("ğŸ” è°ƒè¯•ä¸¢å¤±çš„å†…å®¹")
    print("=" * 80)
    
    test_file = "output/ã€ç«‹é¡¹ç”³è¯·ã€‘é¦–åˆ›è¯åˆ¸æ–°å¢ä»£é”€æœºæ„å¹¿å·å†œå•†è¡Œçš„ç«‹é¡¹ç”³è¯·.doc"
    
    if not os.path.exists(test_file):
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        return
    
    # åˆ›å»ºDocxSplitter
    splitter = DocxSplitter(max_tokens=2000, overlap=200)
    
    print("ğŸ“„ æå–å®Œæ•´æ–‡æ¡£å†…å®¹")
    try:
        from contract_splitter.converter import DocumentConverter
        
        converter = DocumentConverter(cleanup_temp_files=False)
        docx_path = converter.convert_to_docx(test_file)
        
        from docx import Document
        doc = Document(docx_path)
        
        # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
        all_text = ""
        for para in doc.paragraphs:
            if para.text.strip():
                all_text += para.text.strip() + "\n"
        
        # æå–è¡¨æ ¼å†…å®¹
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    cell_content = splitter._extract_nested_tables_from_cell(cell)
                    if cell_content and cell_content.strip():
                        all_text += cell_content.strip() + "\n"
        
        print(f"ğŸ“Š å®Œæ•´æ–‡æ¡£é•¿åº¦: {len(all_text)} å­—ç¬¦")
        
        # æœç´¢ä¸¢å¤±çš„å†…å®¹
        missing_phrases = [
            "å¹¿å·å†œå•†è¡Œå…·æœ‰åŸºé‡‘é”€å”®èµ„æ ¼",
            "å…¬å¸æ²»ç†ç»“æ„å®Œå–„ï¼Œå†…éƒ¨æ§åˆ¶æœ‰æ•ˆ",
            "ç»„ç»‡æ¶æ„å®Œæ•´ï¼Œè®¾æœ‰ä¸“é—¨çš„äº§å“é”€å”®ä¸šåŠ¡å›¢é˜Ÿ",
            "é…å¤‡ç›¸åº”çš„è½¯ç¡¬ä»¶è®¾æ–½",
            "å»ºç«‹äº†äº§å“é”€å”®ä¸šåŠ¡çš„ä¸€æ•´å¥—æµç¨‹å’Œåˆ¶åº¦",
            "ä»£é”€æœºæ„èƒ½å¤Ÿé‡‡å–ç›¸åº”æªæ–½",
            "ä»£é”€æœºæ„åœ¨é”€å”®è¿‡ç¨‹åŠäº§å“å­˜ç»­è¿‡ç¨‹ä¸­",
            "è´Ÿè´£äº§å“é”€å”®ä¸šåŠ¡çš„éƒ¨é—¨è´Ÿè´£äºº",
            "è®¡åˆ’äº§å“é”€å”®ä¸šåŠ¡ä¸å…¬å¸å…¶ä»–ä¸šåŠ¡ä¸å­˜åœ¨åˆ©ç›Šå†²çª",
            "æœ‰å¥å…¨çš„æ¡£æ¡ˆç®¡ç†åˆ¶åº¦",
            "å…­ã€æˆ‘å¸å¯¹äºæ–°å¢ä»£é”€æœºæ„é£é™©åŠç®¡æ§æªæ–½"
        ]
        
        print(f"\nğŸ” æœç´¢ä¸¢å¤±çš„å†…å®¹:")
        for phrase in missing_phrases:
            if phrase in all_text:
                pos = all_text.find(phrase)
                context_start = max(0, pos - 50)
                context_end = min(len(all_text), pos + len(phrase) + 50)
                context = all_text[context_start:context_end]
                print(f"  âœ… æ‰¾åˆ° '{phrase}' at position {pos}")
                print(f"     ä¸Šä¸‹æ–‡: ...{context}...")
            else:
                print(f"  âŒ æœªæ‰¾åˆ° '{phrase}'")
        
        # ç°åœ¨æµ‹è¯•åˆ†å‰²
        print(f"\nğŸ“„ æµ‹è¯•æ–‡æ¡£åˆ†å‰²")
        sections = splitter.split(test_file)
        
        print(f"ğŸ“Š åˆ†å‰²ç»“æœ: {len(sections)} ä¸ªsections")
        
        # æ£€æŸ¥æ¯ä¸ªsectionçš„å†…å®¹
        for i, section in enumerate(sections):
            print(f"\nğŸ“‹ Section {i+1}:")
            if hasattr(section, 'title'):
                print(f"   æ ‡é¢˜: {section.title[:100]}...")
                print(f"   å†…å®¹é•¿åº¦: {len(section.content)} å­—ç¬¦")
                section_text = section.title + "\n" + section.content
            else:
                # sectionæ˜¯dictæ ¼å¼
                print(f"   æ ‡é¢˜: {section.get('title', 'N/A')[:100]}...")
                print(f"   å†…å®¹é•¿åº¦: {len(section.get('content', ''))} å­—ç¬¦")
                section_text = section.get('title', '') + "\n" + section.get('content', '')

            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸¢å¤±çš„å†…å®¹
            found_phrases = []
            for phrase in missing_phrases:
                if phrase in section_text:
                    found_phrases.append(phrase)

            if found_phrases:
                print(f"   âœ… åŒ…å«: {found_phrases}")
            else:
                print(f"   âŒ ä¸åŒ…å«ä»»ä½•ä¸¢å¤±çš„å†…å®¹")

        # åˆå¹¶æ‰€æœ‰sectionå†…å®¹æ£€æŸ¥
        all_section_content = ""
        for section in sections:
            if hasattr(section, 'title'):
                all_section_content += section.title + "\n" + section.content + "\n"
            else:
                all_section_content += section.get('title', '') + "\n" + section.get('content', '') + "\n"
        
        print(f"\nğŸ“Š æ‰€æœ‰sectionsåˆå¹¶é•¿åº¦: {len(all_section_content)} å­—ç¬¦")
        print(f"ğŸ“Š åŸæ–‡æ¡£é•¿åº¦: {len(all_text)} å­—ç¬¦")
        print(f"ğŸ“Š å†…å®¹ä¸¢å¤±: {len(all_text) - len(all_section_content)} å­—ç¬¦")
        
        print(f"\nğŸ” åœ¨åˆå¹¶sectionsä¸­æœç´¢ä¸¢å¤±å†…å®¹:")
        for phrase in missing_phrases:
            if phrase in all_section_content:
                print(f"  âœ… åœ¨sectionsä¸­æ‰¾åˆ° '{phrase}'")
            else:
                print(f"  âŒ åœ¨sectionsä¸­æœªæ‰¾åˆ° '{phrase}'")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å†…å®¹ä¸¢å¤±è°ƒè¯•")
    print("=" * 80)
    
    debug_missing_content()
    
    print("\n" + "=" * 80)
    print("ğŸ¯ è°ƒè¯•å®Œæˆ")


if __name__ == "__main__":
    main()
