#!/usr/bin/env python3
"""
æµ‹è¯•LLMæ ‡é¢˜æ£€æµ‹åŠŸèƒ½
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from contract_splitter import DocxSplitter
from contract_splitter.llm_heading_detector import LLMHeadingDetector


def test_llm_heading_detector_standalone():
    """æµ‹è¯•ç‹¬ç«‹çš„LLMæ ‡é¢˜æ£€æµ‹å™¨"""
    print("ğŸ§  æµ‹è¯•ç‹¬ç«‹LLMæ ‡é¢˜æ£€æµ‹å™¨")
    print("=" * 80)
    
    # åˆ›å»ºæ£€æµ‹å™¨ï¼ˆä¸ä½¿ç”¨çœŸå®LLMï¼Œåªæµ‹è¯•è§„åˆ™å›é€€ï¼‰
    detector = LLMHeadingDetector(llm_client=None)
    
    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "ä¸€ã€é¡¹ç›®åç§°ï¼šé¦–åˆ›è¯åˆ¸æ–°å¢ä»£é”€æœºæ„ - å¹¿å·å†œå•†è¡Œ",
        "ï¼ˆä¸€ï¼‰å…¬å¸æ²»ç†ç»“æ„å®Œå–„ï¼Œå†…éƒ¨æ§åˆ¶æœ‰æ•ˆ ;",
        "ï¼ˆäºŒï¼‰æ»¡è¶³ç›‘ç®¡è¦æ±‚ï¼Œæœªè§ç›‘ç®¡éƒ¨é—¨ï¼ˆè¯ç›‘ä¼šã€å›½å®¶é‡‘èç›‘ç£ç®¡ç†æ€»å±€ï¼‰é’ˆå¯¹è¯¥æœºæ„åŸºé‡‘é”€å”®ä¸šåŠ¡çš„åœä¸šæ•´æ”¹å¤„ç½šï¼Œç¡®ä¿è¯¥ä¸šåŠ¡åœ¨ç›‘ç®¡å…è®¸èŒƒå›´å†…æ­£å¸¸å±•ä¸šï¼›",
        "1ã€ä»£é”€æœºæ„ä¾æ³•æ³¨å†Œï¼Œå¹¶ä¸”æŒç»­ç»è¥ï¼›",
        "2ã€ä»£é”€æœºæ„è‚¡æƒç»“æ„æ¸…æ™°ï¼Œå®é™…æ§åˆ¶äººä¿¡ç”¨æƒ…å†µè‰¯å¥½ï¼›",
        "å››ã€ä»£é”€æœºæ„ä»‹ç»â€”â€” å¹¿å·å†œæ‘å•†ä¸šé“¶è¡Œè‚¡ä»½æœ‰é™å…¬å¸",
        "è¿™æ˜¯ä¸€æ®µæ™®é€šçš„å†…å®¹æ–‡æœ¬ï¼Œä¸åº”è¯¥è¢«è¯†åˆ«ä¸ºæ ‡é¢˜ã€‚å®ƒåŒ…å«äº†å®Œæ•´çš„å¥å­ç»“æ„å’Œæ ‡ç‚¹ç¬¦å·ã€‚",
        "ï¼ˆä¸‰ï¼‰ç»„ç»‡æ¶æ„å®Œæ•´ï¼Œè®¾æœ‰ä¸“é—¨çš„äº§å“é”€å”®ä¸šåŠ¡å›¢é˜Ÿå’Œåˆ†ç®¡é”€å”®ä¸šåŠ¡çš„é«˜ç®¡ï¼Œé”€å”®ä¸šåŠ¡å›¢é˜Ÿçš„è®¾ç½®èƒ½ä¿è¯ä¸šåŠ¡è¿è¥çš„å®Œæ•´ä¸ç‹¬ç«‹ï¼Œé”€å”®ä¸šåŠ¡å›¢é˜Ÿæœ‰æ»¡è¶³è¥ä¸šéœ€è¦çš„å›ºå®šåœºæ‰€å’Œå®‰å…¨é˜²èŒƒæªæ–½ ;"
    ]
    
    # æ‰¹é‡æ£€æµ‹
    results = detector.detect_headings_batch(test_texts)
    
    print("æ£€æµ‹ç»“æœï¼š")
    for i, (text, result) in enumerate(zip(test_texts, results)):
        status = "âœ… æ ‡é¢˜" if result['is_heading'] else "âŒ å†…å®¹"
        level = f"(çº§åˆ«{result['level']})" if result['is_heading'] else ""
        confidence = f"ç½®ä¿¡åº¦{result['confidence']:.2f}"
        print(f"{i+1}. {status} {level} {confidence}")
        print(f"   æ–‡æœ¬: {text[:60]}...")
        print()


def test_docx_splitter_with_llm():
    """æµ‹è¯•é›†æˆLLMçš„DocxSplitter"""
    print("ğŸš€ æµ‹è¯•é›†æˆLLMçš„DocxSplitter")
    print("=" * 80)
    
    test_file = "output/ã€ç«‹é¡¹ç”³è¯·ã€‘é¦–åˆ›è¯åˆ¸æ–°å¢ä»£é”€æœºæ„å¹¿å·å†œå•†è¡Œçš„ç«‹é¡¹ç”³è¯·.doc"
    
    if not os.path.exists(test_file):
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        return
    
    # æµ‹è¯•ä¸ä½¿ç”¨LLMï¼ˆå½“å‰é»˜è®¤è¡Œä¸ºï¼‰
    print("ğŸ“‹ ä¸ä½¿ç”¨LLMçš„ç»“æœï¼š")
    splitter_no_llm = DocxSplitter(use_llm_heading_detection=False)
    sections_no_llm = splitter_no_llm.split(test_file)
    chunks_no_llm = splitter_no_llm.flatten(sections_no_llm)
    print(f"  Sections: {len(sections_no_llm)}")
    print(f"  Chunks: {len(chunks_no_llm)}")
    
    # æµ‹è¯•ä½¿ç”¨LLMï¼ˆä½†æ²¡æœ‰çœŸå®LLMå®¢æˆ·ç«¯ï¼Œä¼šå›é€€åˆ°è§„åˆ™æ£€æµ‹ï¼‰
    print("\nğŸ“‹ å¯ç”¨LLMæ£€æµ‹çš„ç»“æœï¼ˆå›é€€åˆ°è§„åˆ™æ£€æµ‹ï¼‰ï¼š")
    try:
        splitter_with_llm = DocxSplitter(
            use_llm_heading_detection=True,
            llm_config={
                'llm_type': 'custom',
                'client': None  # æ²¡æœ‰çœŸå®å®¢æˆ·ç«¯ï¼Œä¼šå›é€€
            }
        )
        sections_with_llm = splitter_with_llm.split(test_file)
        chunks_with_llm = splitter_with_llm.flatten(sections_with_llm)
        print(f"  Sections: {len(sections_with_llm)}")
        print(f"  Chunks: {len(chunks_with_llm)}")
        
        # æ¯”è¾ƒç»“æœ
        if len(chunks_no_llm) == len(chunks_with_llm):
            print("  âœ… ç»“æœä¸€è‡´ï¼ˆç¬¦åˆé¢„æœŸï¼Œå› ä¸ºå›é€€åˆ°è§„åˆ™æ£€æµ‹ï¼‰")
        else:
            print("  âš ï¸  ç»“æœä¸ä¸€è‡´")
            
    except Exception as e:
        print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")


def test_mock_llm_client():
    """æµ‹è¯•æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯"""
    print("ğŸ¤– æµ‹è¯•æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯")
    print("=" * 80)
    
    class MockLLMClient:
        """æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯"""
        
        def generate(self, prompt: str) -> str:
            """æ¨¡æ‹Ÿç”Ÿæˆå“åº”"""
            # ç®€å•çš„æ¨¡æ‹Ÿé€»è¾‘ï¼šæ ¹æ®æç¤ºä¸­çš„æ–‡æœ¬æ•°é‡è¿”å›ç»“æœ
            import re
            
            # æå–æ–‡æœ¬æ•°é‡
            lines = prompt.split('\n')
            text_lines = [line for line in lines if re.match(r'^\d+\.', line.strip())]
            count = len(text_lines)
            
            # ç”Ÿæˆæ¨¡æ‹Ÿå“åº”
            results = []
            for i in range(count):
                # ç®€å•è§„åˆ™ï¼šåŒ…å«"ä¸€ã€"ã€"äºŒã€"ç­‰çš„æ˜¯1çº§æ ‡é¢˜
                if i < len(text_lines):
                    text = text_lines[i]
                    if any(marker in text for marker in ['ä¸€ã€', 'äºŒã€', 'ä¸‰ã€', 'å››ã€']):
                        results.append({"is_heading": True, "level": 1, "confidence": 0.9})
                    elif any(marker in text for marker in ['ï¼ˆä¸€ï¼‰', 'ï¼ˆäºŒï¼‰', 'ï¼ˆä¸‰ï¼‰']):
                        # æ¨¡æ‹ŸLLMæ›´æ™ºèƒ½çš„åˆ¤æ–­ï¼šé•¿æ–‡æœ¬ä¸æ˜¯æ ‡é¢˜
                        if len(text) > 100:
                            results.append({"is_heading": False, "level": 0, "confidence": 0.8})
                        else:
                            results.append({"is_heading": True, "level": 2, "confidence": 0.7})
                    else:
                        results.append({"is_heading": False, "level": 0, "confidence": 0.6})
                else:
                    results.append({"is_heading": False, "level": 0, "confidence": 0.5})
            
            import json
            return json.dumps(results)
    
    # åˆ›å»ºå¸¦æ¨¡æ‹ŸLLMçš„æ£€æµ‹å™¨
    mock_client = MockLLMClient()
    detector = LLMHeadingDetector(llm_client=mock_client)
    
    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "ä¸€ã€é¡¹ç›®åç§°ï¼šé¦–åˆ›è¯åˆ¸æ–°å¢ä»£é”€æœºæ„ - å¹¿å·å†œå•†è¡Œ",
        "ï¼ˆä¸€ï¼‰å…¬å¸æ²»ç†ç»“æ„å®Œå–„ï¼Œå†…éƒ¨æ§åˆ¶æœ‰æ•ˆ ;",
        "ï¼ˆäºŒï¼‰æ»¡è¶³ç›‘ç®¡è¦æ±‚ï¼Œæœªè§ç›‘ç®¡éƒ¨é—¨ï¼ˆè¯ç›‘ä¼šã€å›½å®¶é‡‘èç›‘ç£ç®¡ç†æ€»å±€ï¼‰é’ˆå¯¹è¯¥æœºæ„åŸºé‡‘é”€å”®ä¸šåŠ¡çš„åœä¸šæ•´æ”¹å¤„ç½šï¼Œç¡®ä¿è¯¥ä¸šåŠ¡åœ¨ç›‘ç®¡å…è®¸èŒƒå›´å†…æ­£å¸¸å±•ä¸šï¼›",
        "è¿™æ˜¯æ™®é€šå†…å®¹"
    ]
    
    # æ‰¹é‡æ£€æµ‹
    results = detector.detect_headings_batch(test_texts)
    
    print("æ¨¡æ‹ŸLLMæ£€æµ‹ç»“æœï¼š")
    for i, (text, result) in enumerate(zip(test_texts, results)):
        status = "âœ… æ ‡é¢˜" if result['is_heading'] else "âŒ å†…å®¹"
        level = f"(çº§åˆ«{result['level']})" if result['is_heading'] else ""
        confidence = f"ç½®ä¿¡åº¦{result['confidence']:.2f}"
        print(f"{i+1}. {status} {level} {confidence}")
        print(f"   æ–‡æœ¬: {text[:60]}...")
        print()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§  LLMæ ‡é¢˜æ£€æµ‹åŠŸèƒ½æµ‹è¯•")
    print("=" * 80)
    
    test_llm_heading_detector_standalone()
    print("\n" + "=" * 80)
    
    test_docx_splitter_with_llm()
    print("\n" + "=" * 80)
    
    test_mock_llm_client()
    
    print("\n" + "=" * 80)
    print("ğŸ’¡ ä½¿ç”¨è¯´æ˜ï¼š")
    print("1. LLMæ ‡é¢˜æ£€æµ‹æ˜¯å¯é€‰åŠŸèƒ½ï¼Œé»˜è®¤å…³é—­")
    print("2. å¯ç”¨æ—¶éœ€è¦æä¾›LLMå®¢æˆ·ç«¯é…ç½®")
    print("3. å¦‚æœLLMä¸å¯ç”¨ï¼Œä¼šè‡ªåŠ¨å›é€€åˆ°è§„åˆ™æ£€æµ‹")
    print("4. LLMæ£€æµ‹é‡‡ç”¨æ‰¹é‡å¤„ç†ï¼Œæé«˜æ•ˆç‡")
    print("5. è€ƒè™‘tokené™åˆ¶ï¼Œæ™ºèƒ½åˆ†æ‰¹å¤„ç†")
    
    print("\nğŸ”§ é…ç½®ç¤ºä¾‹ï¼š")
    print("""
# ä½¿ç”¨OpenAI
splitter = DocxSplitter(
    use_llm_heading_detection=True,
    llm_config={
        'llm_type': 'openai',
        'api_key': 'your-api-key'
    }
)

# ä½¿ç”¨Claude
splitter = DocxSplitter(
    use_llm_heading_detection=True,
    llm_config={
        'llm_type': 'claude',
        'api_key': 'your-api-key'
    }
)

# ä½¿ç”¨è‡ªå®šä¹‰å®¢æˆ·ç«¯
splitter = DocxSplitter(
    use_llm_heading_detection=True,
    llm_config={
        'llm_type': 'custom',
        'client': your_llm_client
    }
)
""")


if __name__ == "__main__":
    main()
