#!/usr/bin/env python3
"""
æµ‹è¯•å±‚æ¬¡åŒ–æ³•å¾‹æ¡æ–‡åˆ‡åˆ†åŠŸèƒ½
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from contract_splitter.domain_helpers import split_legal_document


def test_hierarchical_legal_splitting():
    """æµ‹è¯•å±‚æ¬¡åŒ–æ³•å¾‹æ¡æ–‡åˆ‡åˆ†"""
    
    print("ğŸ” å±‚æ¬¡åŒ–æ³•å¾‹æ¡æ–‡åˆ‡åˆ†æµ‹è¯•")
    print("=" * 80)
    
    # æµ‹è¯•æ–‡ä»¶åˆ—è¡¨
    test_files = [
        'output/law/9147de404f6d4df986b0cb41acd47aac.wps',
        'output/law/è¯åˆ¸å…¬å¸ç›‘ç£ç®¡ç†æ¡ä¾‹(2014å¹´ä¿®è®¢).docx',
        'output/law/é™„ä»¶1.æœŸè´§å…¬å¸äº’è”ç½‘è¥é”€ç®¡ç†æš‚è¡Œè§„å®š.pdf'
    ]
    
    results = {}
    
    for test_file in test_files:
        if not os.path.exists(test_file):
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
            continue
            
        file_name = os.path.basename(test_file)
        print(f"\nğŸ“„ æµ‹è¯•æ–‡ä»¶: {file_name}")
        print("-" * 60)
        
        try:
            # ä½¿ç”¨å±‚æ¬¡åŒ–åˆ‡åˆ†
            chunks = split_legal_document(test_file, max_tokens=1500)
            
            results[file_name] = {
                'success': True,
                'chunks_count': len(chunks),
                'chunks': chunks
            }
            
            print(f"âœ… å¤„ç†æˆåŠŸ: {len(chunks)} chunks")
            
            # åˆ†æchunkç»“æ„
            analyze_chunk_structure(chunks, file_name)
            
        except Exception as e:
            results[file_name] = {
                'success': False,
                'error': str(e)
            }
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    generate_summary_report(results)
    
    return results


def analyze_chunk_structure(chunks, file_name):
    """åˆ†æchunkç»“æ„"""
    import sys
    import os
    sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

    from contract_splitter.legal_structure_detector import get_legal_detector, LegalStructureLevel

    print(f"\nğŸ“Š {file_name} ç»“æ„åˆ†æ:")

    # ç»Ÿè®¡ä¸åŒå±‚æ¬¡çš„chunkæ•°é‡
    structure_stats = {
        'chapter': 0,    # ç« èŠ‚
        'article': 0,    # æ¡æ–‡
        'item': 0,       # åºå·
        'content': 0     # æ™®é€šå†…å®¹
    }

    # ä½¿ç”¨ç»Ÿä¸€çš„ç»“æ„æ£€æµ‹å™¨
    detector = get_legal_detector("legal")
    
    for chunk in chunks:
        chunk_type = 'content'

        # ä½¿ç”¨ç»Ÿä¸€çš„ç»“æ„æ£€æµ‹å™¨åˆ¤æ–­ç±»å‹
        if detector.is_legal_heading(chunk):
            level = detector.get_heading_level(chunk)
            if level == LegalStructureLevel.CHAPTER.value or level == LegalStructureLevel.BOOK.value:
                chunk_type = 'chapter'
            elif level == LegalStructureLevel.ARTICLE.value:
                chunk_type = 'article'
            elif level >= LegalStructureLevel.ENUMERATION.value:
                chunk_type = 'item'

        structure_stats[chunk_type] += 1
    
    # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
    for type_name, count in structure_stats.items():
        if count > 0:
            print(f"  {type_name}: {count}")
    
    # æ˜¾ç¤ºå‰3ä¸ªchunkçš„é¢„è§ˆ
    print(f"\nğŸ“ å‰3ä¸ªchunksé¢„è§ˆ:")
    for i, chunk in enumerate(chunks[:3], 1):
        print(f"\n  Chunk {i} (é•¿åº¦: {len(chunk)}):")
        print("  " + "-" * 38)
        # æ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦
        preview = chunk[:200].replace('\n', ' ')
        if len(chunk) > 200:
            preview += "..."
        print(f"  {preview}")


def generate_summary_report(results):
    """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
    print("\n" + "=" * 80)
    print("ğŸ“Š å±‚æ¬¡åŒ–åˆ‡åˆ†æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    
    total_files = len(results)
    successful_files = sum(1 for r in results.values() if r['success'])
    total_chunks = sum(r.get('chunks_count', 0) for r in results.values() if r['success'])
    
    print(f"æ€»æ–‡ä»¶æ•°: {total_files}")
    print(f"æˆåŠŸå¤„ç†: {successful_files}")
    print(f"æˆåŠŸç‡: {successful_files/total_files*100:.1f}%")
    print(f"æ€»chunksæ•°: {total_chunks}")
    
    if successful_files > 0:
        avg_chunks = total_chunks / successful_files
        print(f"å¹³å‡chunksæ•°: {avg_chunks:.1f}")
    
    print("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
    for file_name, result in results.items():
        if result['success']:
            print(f"  âœ… {file_name}: {result['chunks_count']} chunks")
        else:
            print(f"  âŒ {file_name}: {result['error']}")


def compare_with_previous_results():
    """ä¸ä¹‹å‰çš„ç»“æœå¯¹æ¯”"""
    print("\nğŸ”„ ä¸ä¹‹å‰ç»“æœå¯¹æ¯”:")
    print("-" * 40)
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ ä¸ä¹‹å‰ç»“æœçš„å¯¹æ¯”é€»è¾‘
    # æ¯”å¦‚ä»ä¿å­˜çš„ç»“æœæ–‡ä»¶ä¸­è¯»å–ä¹‹å‰çš„æ•°æ®è¿›è¡Œå¯¹æ¯”
    
    previous_results = {
        '9147de404f6d4df986b0cb41acd47aac.wps': 4,  # ä¹‹å‰çš„ç»“æœ
        'è¯åˆ¸å…¬å¸ç›‘ç£ç®¡ç†æ¡ä¾‹(2014å¹´ä¿®è®¢).docx': 22,
    }
    
    current_results = test_hierarchical_legal_splitting()
    
    for file_name in previous_results:
        if file_name in current_results and current_results[file_name]['success']:
            prev_count = previous_results[file_name]
            curr_count = current_results[file_name]['chunks_count']
            change = curr_count - prev_count
            change_pct = (change / prev_count) * 100 if prev_count > 0 else 0
            
            print(f"  {file_name}:")
            print(f"    ä¹‹å‰: {prev_count} chunks")
            print(f"    ç°åœ¨: {curr_count} chunks")
            print(f"    å˜åŒ–: {change:+d} ({change_pct:+.1f}%)")


if __name__ == "__main__":
    test_hierarchical_legal_splitting()
