#!/usr/bin/env python3
"""
æµ‹è¯•output/lawç›®å½•ä¸‹çš„WPSå’ŒPDFæ–‡ä»¶æ‹†åˆ†æ•ˆæœ
å¹¶å°†ç»“æœä¿å­˜åˆ°txtæ–‡ä»¶ä¾›äººå·¥å¤æ ¸
"""

import os
import glob
import json
import time
from pathlib import Path
from datetime import datetime
from contract_splitter.domain_helpers import split_legal_document

def find_law_documents():
    """æŸ¥æ‰¾output/lawç›®å½•ä¸‹çš„WPSå’ŒPDFæ–‡ä»¶"""
    law_dir = "output/law"
    
    # æŸ¥æ‰¾WPSå’ŒPDFæ–‡ä»¶
    wps_files = glob.glob(f"{law_dir}/*.wps")
    pdf_files = glob.glob(f"{law_dir}/*.pdf")
    
    return sorted(wps_files + pdf_files)

def safe_filename(filename):
    """åˆ›å»ºå®‰å…¨çš„æ–‡ä»¶å"""
    # ç§»é™¤æˆ–æ›¿æ¢ä¸å®‰å…¨çš„å­—ç¬¦
    safe_chars = []
    for char in filename:
        if char.isalnum() or char in '.-_':
            safe_chars.append(char)
        elif char in ' /\\':
            safe_chars.append('_')
    
    result = ''.join(safe_chars)
    # é™åˆ¶é•¿åº¦
    if len(result) > 100:
        result = result[:100]
    
    return result

def save_chunks_to_txt(chunks, output_file, file_path, processing_time):
    """å°†chunksä¿å­˜åˆ°txtæ–‡ä»¶"""
    with open(output_file, 'w', encoding='utf-8') as f:
        # å†™å…¥æ–‡ä»¶å¤´ä¿¡æ¯
        f.write("=" * 80 + "\n")
        f.write("æ³•å¾‹æ–‡æ¡£æ‹†åˆ†ç»“æœ - äººå·¥å¤æ ¸ç‰ˆ\n")
        f.write("=" * 80 + "\n")
        f.write(f"åŸæ–‡ä»¶: {file_path}\n")
        f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"å¤„ç†è€—æ—¶: {processing_time:.2f}ç§’\n")
        f.write(f"æ€»chunksæ•°: {len(chunks)}\n")
        f.write(f"å¹³å‡é•¿åº¦: {sum(len(chunk) for chunk in chunks) / len(chunks):.1f}å­—ç¬¦\n")
        f.write("=" * 80 + "\n\n")
        
        # å†™å…¥æ¯ä¸ªchunk
        for i, chunk in enumerate(chunks, 1):
            f.write(f"ã€Chunk {i:03d}ã€‘ (é•¿åº¦: {len(chunk)} å­—ç¬¦)\n")
            f.write("-" * 60 + "\n")
            f.write(chunk)
            f.write("\n")
            f.write("=" * 80 + "\n\n")
        
        # å†™å…¥ç»Ÿè®¡ä¿¡æ¯
        f.write("ç»Ÿè®¡ä¿¡æ¯:\n")
        f.write("-" * 40 + "\n")
        
        # é•¿åº¦åˆ†å¸ƒ
        length_ranges = {
            '0-50': 0, '51-100': 0, '101-200': 0, 
            '201-300': 0, '301-500': 0, '500+': 0
        }
        
        for chunk in chunks:
            length = len(chunk)
            if length <= 50:
                length_ranges['0-50'] += 1
            elif length <= 100:
                length_ranges['51-100'] += 1
            elif length <= 200:
                length_ranges['101-200'] += 1
            elif length <= 300:
                length_ranges['201-300'] += 1
            elif length <= 500:
                length_ranges['301-500'] += 1
            else:
                length_ranges['500+'] += 1
        
        f.write("é•¿åº¦åˆ†å¸ƒ:\n")
        for range_name, count in length_ranges.items():
            percentage = (count / len(chunks)) * 100
            f.write(f"  {range_name}å­—ç¬¦: {count}ä¸ª ({percentage:.1f}%)\n")
        
        # æ¡æ–‡åˆ†æï¼ˆå¦‚æœæ˜¯æ³•å¾‹æ–‡æ¡£ï¼‰
        import re
        article_chunks = []
        for i, chunk in enumerate(chunks, 1):
            if re.search(r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+æ¡', chunk):
                article_chunks.append((i, chunk))
        
        if article_chunks:
            f.write(f"\næ¡æ–‡åˆ†æ:\n")
            f.write(f"  åŒ…å«æ¡æ–‡çš„chunks: {len(article_chunks)}ä¸ª\n")
            f.write(f"  æ¡æ–‡è¦†ç›–ç‡: {len(article_chunks)/len(chunks)*100:.1f}%\n")
            
            # åˆ—å‡ºå‰10ä¸ªæ¡æ–‡
            f.write(f"  å‰10ä¸ªæ¡æ–‡:\n")
            for i, (chunk_num, chunk) in enumerate(article_chunks[:10]):
                article_match = re.search(r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+æ¡', chunk)
                if article_match:
                    article_title = article_match.group()
                    f.write(f"    Chunk {chunk_num}: {article_title}\n")

def test_single_file(file_path):
    """æµ‹è¯•å•ä¸ªæ–‡ä»¶"""
    print(f"\nğŸ” æµ‹è¯•æ–‡ä»¶: {file_path}")
    print("-" * 60)
    
    try:
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # å¤„ç†æ–‡ä»¶
        chunks = split_legal_document(file_path, max_tokens=1500)
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        processing_time = end_time - start_time
        
        print(f"âœ… å¤„ç†æˆåŠŸ: {len(chunks)} chunks")
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
        
        if chunks:
            avg_length = sum(len(chunk) for chunk in chunks) / len(chunks)
            max_length = max(len(chunk) for chunk in chunks)
            min_length = min(len(chunk) for chunk in chunks)
            
            print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   å¹³å‡é•¿åº¦: {avg_length:.1f} å­—ç¬¦")
            print(f"   æœ€å¤§é•¿åº¦: {max_length} å­—ç¬¦")
            print(f"   æœ€å°é•¿åº¦: {min_length} å­—ç¬¦")
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å
            file_stem = Path(file_path).stem
            safe_name = safe_filename(file_stem)
            output_file = f"output/law_review/{safe_name}_chunks.txt"
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs("output/law_review", exist_ok=True)
            
            # ä¿å­˜ç»“æœ
            save_chunks_to_txt(chunks, output_file, file_path, processing_time)
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {output_file}")
            
            return True, len(chunks), processing_time
        else:
            print("âš ï¸  æ²¡æœ‰ç”Ÿæˆchunks")
            return False, 0, processing_time
            
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        return False, 0, 0

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•output/lawç›®å½•ä¸‹çš„WPSå’ŒPDFæ–‡ä»¶")
    print("=" * 80)
    
    # æŸ¥æ‰¾æ–‡ä»¶
    files = find_law_documents()
    
    if not files:
        print("âŒ æœªæ‰¾åˆ°WPSæˆ–PDFæ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶:")
    for i, file_path in enumerate(files, 1):
        file_type = "WPS" if file_path.endswith('.wps') else "PDF"
        print(f"   {i:2d}. [{file_type}] {os.path.basename(file_path)}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("output/law_review", exist_ok=True)
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    results = []
    total_start_time = time.time()
    
    for file_path in files:
        success, chunk_count, processing_time = test_single_file(file_path)
        results.append({
            'file': os.path.basename(file_path),
            'success': success,
            'chunks': chunk_count,
            'time': processing_time
        })
    
    total_end_time = time.time()
    total_time = total_end_time - total_start_time
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print("\n" + "=" * 80)
    print("ğŸ“Š å¤„ç†ç»“æœæ€»ç»“")
    print("=" * 80)
    
    successful_files = [r for r in results if r['success']]
    failed_files = [r for r in results if not r['success']]
    
    print(f"âœ… æˆåŠŸå¤„ç†: {len(successful_files)}/{len(files)} ä¸ªæ–‡ä»¶")
    print(f"âŒ å¤„ç†å¤±è´¥: {len(failed_files)} ä¸ªæ–‡ä»¶")
    print(f"â±ï¸  æ€»å¤„ç†æ—¶é—´: {total_time:.2f}ç§’")
    
    if successful_files:
        total_chunks = sum(r['chunks'] for r in successful_files)
        avg_chunks = total_chunks / len(successful_files)
        avg_time = sum(r['time'] for r in successful_files) / len(successful_files)
        
        print(f"ğŸ“ˆ æˆåŠŸæ–‡ä»¶ç»Ÿè®¡:")
        print(f"   æ€»chunksæ•°: {total_chunks}")
        print(f"   å¹³å‡chunksæ•°: {avg_chunks:.1f}")
        print(f"   å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.2f}ç§’")
    
    if failed_files:
        print(f"\nâŒ å¤±è´¥æ–‡ä»¶:")
        for result in failed_files:
            print(f"   - {result['file']}")
    
    print(f"\nğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: output/law_review/")
    print(f"ğŸ’¡ è¯·äººå·¥å¤æ ¸txtæ–‡ä»¶ä¸­çš„æ‹†åˆ†æ•ˆæœ")

if __name__ == "__main__":
    main()
