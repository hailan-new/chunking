#!/usr/bin/env python3
"""
é«˜çº§åˆ†å—ç­–ç•¥ç¤ºä¾‹
æ¼”ç¤ºContract Splitterçš„é«˜çº§åŠŸèƒ½å’Œè‡ªå®šä¹‰åˆ†å—ç­–ç•¥
"""

import sys
from pathlib import Path
import tempfile
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

def demo_sentence_priority_vs_strict_chunking():
    """æ¼”ç¤ºå¥å­ä¼˜å…ˆåˆ†å— vs ä¸¥æ ¼å­—ç¬¦åˆ†å—çš„å¯¹æ¯”"""
    print("ğŸ¯ å¥å­ä¼˜å…ˆåˆ†å— vs ä¸¥æ ¼å­—ç¬¦åˆ†å—å¯¹æ¯”")
    print("=" * 60)
    
    from contract_splitter.utils import sliding_window_split
    
    # æµ‹è¯•æ–‡æœ¬ - åŒ…å«å®Œæ•´çš„æ³•å¾‹æ¡æ–‡
    test_text = """
    ç¬¬ä¸€æ¡ ä¸ºäº†è§„èŒƒè¯åˆ¸å…¬å¸åˆ†ç±»ç›‘ç®¡ï¼Œåˆç†é…ç½®ç›‘ç®¡èµ„æºï¼Œæé«˜ç›‘ç®¡æ•ˆç‡ï¼Œä¿ƒè¿›è¯åˆ¸ä¸šå¥åº·å‘å±•ï¼Œæ ¹æ®ã€Šè¯åˆ¸æ³•ã€‹ã€ã€Šè¯åˆ¸å…¬å¸ç›‘ç£ç®¡ç†æ¡ä¾‹ã€‹ç­‰æ³•å¾‹æ³•è§„ï¼Œåˆ¶å®šæœ¬è§„å®šã€‚ç¬¬äºŒæ¡ æœ¬è§„å®šé€‚ç”¨äºåœ¨ä¸­åäººæ°‘å…±å’Œå›½å¢ƒå†…ä¾æ³•è®¾ç«‹çš„è¯åˆ¸å…¬å¸ã€‚ç¬¬ä¸‰æ¡ ä¸­å›½è¯ç›‘ä¼šåŠå…¶æ´¾å‡ºæœºæ„ä¾ç…§æœ¬è§„å®šå¯¹è¯åˆ¸å…¬å¸è¿›è¡Œåˆ†ç±»ç›‘ç®¡ã€‚ç¬¬å››æ¡ è¯åˆ¸å…¬å¸åˆ†ç±»ç›‘ç®¡æ˜¯æŒ‡ä¸­å›½è¯ç›‘ä¼šæ ¹æ®è¯åˆ¸å…¬å¸é£é™©ç®¡ç†èƒ½åŠ›ã€æŒç»­åˆè§„çŠ¶å†µç­‰å› ç´ ï¼Œå°†è¯åˆ¸å…¬å¸åˆ†ä¸ºä¸åŒç±»åˆ«ï¼Œå¹¶æ®æ­¤å¯¹è¯åˆ¸å…¬å¸å®æ–½å·®åˆ«åŒ–ç›‘ç®¡çš„åˆ¶åº¦ã€‚ç¬¬äº”æ¡ è¯åˆ¸å…¬å¸åˆ†ç±»è¯„ä»·æ¯å¹´è¿›è¡Œä¸€æ¬¡ï¼Œè¯„ä»·åŸºå‡†æ—¥ä¸ºæ¯å¹´çš„12æœˆ31æ—¥ã€‚è¯„ä»·ç»“æœæœ‰æ•ˆæœŸä¸ºä¸€å¹´ã€‚
    """.strip()
    
    print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")
    
    # æµ‹è¯•é…ç½®
    max_tokens = 200
    overlap = 40
    
    print(f"\nğŸ”§ æµ‹è¯•é…ç½®: max_tokens={max_tokens}, overlap={overlap}")
    
    # 1. å¥å­ä¼˜å…ˆåˆ†å— (æ¨èæ–¹å¼)
    print(f"\nâœ… å¥å­ä¼˜å…ˆåˆ†å— (æ¨è):")
    chunks_sentence = sliding_window_split(
        test_text,
        max_tokens=max_tokens,
        overlap=overlap,
        by_sentence=True,  # å¥å­ä¼˜å…ˆ
        token_counter="character"
    )
    
    sentence_complete = 0
    for i, chunk in enumerate(chunks_sentence, 1):
        ends_complete = chunk.strip().endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', '.', '!', '?', ';'))
        if ends_complete:
            sentence_complete += 1
            status = "âœ…"
        else:
            status = "âš ï¸"
        
        print(f"   Chunk {i} ({len(chunk)}å­—ç¬¦) {status}: {chunk[:80]}...")
        if not ends_complete:
            print(f"      ç»“å°¾: ...{chunk[-30:]}")
    
    # 2. ä¸¥æ ¼å­—ç¬¦åˆ†å— (ä¼ ç»Ÿæ–¹å¼)
    print(f"\nâŒ ä¸¥æ ¼å­—ç¬¦åˆ†å— (ä¼ ç»Ÿ):")
    chunks_strict = sliding_window_split(
        test_text,
        max_tokens=max_tokens,
        overlap=overlap,
        by_sentence=False,  # ä¸¥æ ¼å­—ç¬¦é™åˆ¶
        token_counter="character"
    )
    
    strict_complete = 0
    for i, chunk in enumerate(chunks_strict, 1):
        ends_complete = chunk.strip().endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', '.', '!', '?', ';'))
        if ends_complete:
            strict_complete += 1
            status = "âœ…"
        else:
            status = "âš ï¸"
        
        print(f"   Chunk {i} ({len(chunk)}å­—ç¬¦) {status}: {chunk[:80]}...")
        if not ends_complete:
            print(f"      ç»“å°¾: ...{chunk[-30:]}")
    
    # 3. å¯¹æ¯”ç»“æœ
    print(f"\nğŸ“Š å¯¹æ¯”ç»“æœ:")
    sentence_rate = sentence_complete / len(chunks_sentence) * 100
    strict_rate = strict_complete / len(chunks_strict) * 100
    improvement = sentence_rate - strict_rate
    
    print(f"   å¥å­ä¼˜å…ˆåˆ†å—: {sentence_complete}/{len(chunks_sentence)} å®Œæ•´ ({sentence_rate:.1f}%)")
    print(f"   ä¸¥æ ¼å­—ç¬¦åˆ†å—: {strict_complete}/{len(chunks_strict)} å®Œæ•´ ({strict_rate:.1f}%)")
    print(f"   ğŸš€ æ”¹è¿›å¹…åº¦: +{improvement:.1f}% å¥å­å®Œæ•´ç‡æå‡")


def demo_hierarchical_strategies():
    """æ¼”ç¤ºä¸åŒçš„å±‚æ¬¡åŒ–åˆ†å—ç­–ç•¥"""
    print("\n\nğŸ“Š å±‚æ¬¡åŒ–åˆ†å—ç­–ç•¥å¯¹æ¯”")
    print("=" * 60)
    
    from contract_splitter import split_document, flatten_sections
    
    # ä½¿ç”¨ç¤ºä¾‹æ–‡æ¡£
    document_path = "output/law/é™„ä»¶1.å…³äºä¿®æ”¹ã€Šè¯åˆ¸å…¬å¸åˆ†ç±»ç›‘ç®¡è§„å®šã€‹çš„å†³å®š.pdf"
    
    if not Path(document_path).exists():
        print(f"âš ï¸ ç¤ºä¾‹æ–‡æ¡£ä¸å­˜åœ¨: {document_path}")
        return
    
    try:
        print(f"ğŸ“„ å¤„ç†æ–‡æ¡£: {Path(document_path).name}")
        
        # è·å–å±‚æ¬¡åŒ–sections
        sections = split_document(document_path, max_tokens=800)
        print(f"   åŸå§‹sections: {len(sections)} ä¸ª")
        
        # æµ‹è¯•ä¸åŒçš„æ‰å¹³åŒ–ç­–ç•¥
        strategies = [
            ("finest_granularity", "æœ€ç»†ç²’åº¦ - è·å–æœ€å°çš„æ–‡æ¡£å•å…ƒ"),
            ("all_levels", "æ‰€æœ‰å±‚çº§ - åŒ…å«å„å±‚çº§çš„å®Œæ•´å†…å®¹"),
            ("parent_only", "ä»…çˆ¶çº§ - åªä¿ç•™é¡¶çº§sections")
        ]
        
        for strategy, description in strategies:
            print(f"\nğŸ”§ ç­–ç•¥: {strategy}")
            print(f"   æè¿°: {description}")
            
            chunks = flatten_sections(sections, strategy=strategy)
            
            # åˆ†æç»“æœ
            chunk_sizes = [len(chunk.content) for chunk in chunks]
            avg_size = sum(chunk_sizes) / len(chunk_sizes) if chunk_sizes else 0
            max_size = max(chunk_sizes) if chunk_sizes else 0
            min_size = min(chunk_sizes) if chunk_sizes else 0
            
            print(f"   ğŸ“Š ç»“æœ: {len(chunks)} ä¸ªchunks")
            print(f"   ğŸ“ å¤§å°: å¹³å‡{avg_size:.0f}, æœ€å¤§{max_size}, æœ€å°{min_size} å­—ç¬¦")
            
            # æ˜¾ç¤ºå±‚çº§åˆ†å¸ƒ
            level_distribution = {}
            for chunk in chunks:
                level = getattr(chunk, 'level', 0)
                level_distribution[level] = level_distribution.get(level, 0) + 1
            
            print(f"   ğŸ“‹ å±‚çº§åˆ†å¸ƒ: {dict(sorted(level_distribution.items()))}")
            
            # æ˜¾ç¤ºå‰2ä¸ªchunksç¤ºä¾‹
            print(f"   ğŸ“ ç¤ºä¾‹chunks:")
            for i, chunk in enumerate(chunks[:2], 1):
                level = getattr(chunk, 'level', 0)
                content_preview = chunk.content[:100] + "..." if len(chunk.content) > 100 else chunk.content
                print(f"      {i}. Level {level}: {content_preview}")
    
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")


def demo_custom_chunking_parameters():
    """æ¼”ç¤ºè‡ªå®šä¹‰åˆ†å—å‚æ•°çš„æ•ˆæœ"""
    print("\n\nğŸ”§ è‡ªå®šä¹‰åˆ†å—å‚æ•°æ•ˆæœå¯¹æ¯”")
    print("=" * 60)
    
    from contract_splitter import simple_chunk_file
    
    # ä½¿ç”¨ç¤ºä¾‹æ–‡æ¡£
    document_path = "output/law/é™„ä»¶1.æœŸè´§å…¬å¸äº’è”ç½‘è¥é”€ç®¡ç†æš‚è¡Œè§„å®š.pdf"
    
    if not Path(document_path).exists():
        print(f"âš ï¸ ç¤ºä¾‹æ–‡æ¡£ä¸å­˜åœ¨: {document_path}")
        return
    
    # æµ‹è¯•ä¸åŒçš„å‚æ•°ç»„åˆ
    parameter_sets = [
        {"max_chunk_size": 200, "overlap_ratio": 0.05, "name": "å°å—ä½é‡å "},
        {"max_chunk_size": 200, "overlap_ratio": 0.25, "name": "å°å—é«˜é‡å "},
        {"max_chunk_size": 600, "overlap_ratio": 0.1, "name": "ä¸­å—æ ‡å‡†é‡å "},
        {"max_chunk_size": 1200, "overlap_ratio": 0.15, "name": "å¤§å—é€‚ä¸­é‡å "},
    ]
    
    try:
        print(f"ğŸ“„ æµ‹è¯•æ–‡æ¡£: {Path(document_path).name}")
        
        for params in parameter_sets:
            print(f"\nğŸ”§ å‚æ•°ç»„åˆ: {params['name']}")
            print(f"   max_chunk_size: {params['max_chunk_size']}")
            print(f"   overlap_ratio: {params['overlap_ratio']}")
            
            chunks = simple_chunk_file(
                document_path,
                max_chunk_size=params['max_chunk_size'],
                overlap_ratio=params['overlap_ratio']
            )
            
            # åˆ†æç»“æœ
            chunk_sizes = [len(chunk['content']) for chunk in chunks]
            avg_size = sum(chunk_sizes) / len(chunk_sizes)
            max_size = max(chunk_sizes)
            min_size = min(chunk_sizes)
            
            # è®¡ç®—å®é™…é‡å 
            total_chars = sum(chunk_sizes)
            original_size = len(open(document_path, 'rb').read())  # è¿‘ä¼¼åŸå§‹å¤§å°
            
            print(f"   ğŸ“Š ç»“æœ:")
            print(f"      - Chunksæ•°é‡: {len(chunks)}")
            print(f"      - å¹³å‡å¤§å°: {avg_size:.0f} å­—ç¬¦")
            print(f"      - å¤§å°èŒƒå›´: {min_size} - {max_size} å­—ç¬¦")
            print(f"      - æ€»å­—ç¬¦æ•°: {total_chars}")
            
            # æ£€æŸ¥å¥å­å®Œæ•´æ€§
            complete_sentences = sum(1 for chunk in chunks 
                                   if chunk['content'].strip().endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', '.', '!', '?', ';')))
            completion_rate = complete_sentences / len(chunks) * 100
            print(f"      - å¥å­å®Œæ•´ç‡: {completion_rate:.1f}%")
            
            # æ˜¾ç¤ºç¬¬ä¸€ä¸ªchunkç¤ºä¾‹
            if chunks:
                first_chunk = chunks[0]['content']
                preview = first_chunk[:120] + "..." if len(first_chunk) > 120 else first_chunk
                print(f"   ğŸ“ é¦–ä¸ªchunk: {preview}")
    
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")


def demo_token_counting_methods():
    """æ¼”ç¤ºä¸åŒçš„tokenè®¡æ•°æ–¹æ³•"""
    print("\n\nğŸ”¢ Tokenè®¡æ•°æ–¹æ³•å¯¹æ¯”")
    print("=" * 60)
    
    from contract_splitter.utils import sliding_window_split, count_tokens
    
    # æµ‹è¯•æ–‡æœ¬
    test_text = "ç¬¬ä¸€æ¡ ä¸ºäº†è§„èŒƒè¯åˆ¸å…¬å¸åˆ†ç±»ç›‘ç®¡ï¼Œåˆç†é…ç½®ç›‘ç®¡èµ„æºï¼Œæé«˜ç›‘ç®¡æ•ˆç‡ï¼Œä¿ƒè¿›è¯åˆ¸ä¸šå¥åº·å‘å±•ï¼Œåˆ¶å®šæœ¬è§„å®šã€‚"
    
    print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬: {test_text}")
    print(f"   æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")
    
    # æµ‹è¯•ä¸åŒçš„è®¡æ•°æ–¹æ³•
    counting_methods = ["character", "tiktoken"]
    
    for method in counting_methods:
        try:
            print(f"\nğŸ”¢ è®¡æ•°æ–¹æ³•: {method}")
            
            # è®¡ç®—tokenæ•°
            token_count = count_tokens(test_text, method)
            print(f"   Tokenæ•°é‡: {token_count}")
            
            # ä½¿ç”¨è¯¥æ–¹æ³•è¿›è¡Œåˆ†å—
            chunks = sliding_window_split(
                test_text,
                max_tokens=50,
                overlap=10,
                by_sentence=True,
                token_counter=method
            )
            
            print(f"   åˆ†å—ç»“æœ: {len(chunks)} ä¸ªchunks")
            for i, chunk in enumerate(chunks, 1):
                chunk_tokens = count_tokens(chunk, method)
                print(f"      Chunk {i}: {chunk_tokens} tokens, {len(chunk)} å­—ç¬¦")
                print(f"         å†…å®¹: {chunk}")
        
        except Exception as e:
            print(f"   âŒ {method} æ–¹æ³•å¤±è´¥: {str(e)}")


def demo_overlap_analysis():
    """æ¼”ç¤ºé‡å åˆ†æ"""
    print("\n\nğŸ”„ é‡å åˆ†æ")
    print("=" * 60)
    
    from contract_splitter.utils import sliding_window_split
    
    # æµ‹è¯•æ–‡æœ¬
    test_text = """
    ç¬¬ä¸€æ¡ è¿™æ˜¯ç¬¬ä¸€ä¸ªæ¡æ–‡çš„å†…å®¹ï¼ŒåŒ…å«äº†é‡è¦çš„æ³•å¾‹è§„å®šã€‚ç¬¬äºŒæ¡ è¿™æ˜¯ç¬¬äºŒä¸ªæ¡æ–‡çš„å†…å®¹ï¼Œä¸ç¬¬ä¸€æ¡æœ‰ä¸€å®šçš„å…³è”æ€§ã€‚ç¬¬ä¸‰æ¡ è¿™æ˜¯ç¬¬ä¸‰ä¸ªæ¡æ–‡çš„å†…å®¹ï¼Œè¿›ä¸€æ­¥ç»†åŒ–äº†ç›¸å…³è§„å®šã€‚ç¬¬å››æ¡ è¿™æ˜¯ç¬¬å››ä¸ªæ¡æ–‡çš„å†…å®¹ï¼Œæä¾›äº†å…·ä½“çš„å®æ–½ç»†åˆ™ã€‚
    """.strip()
    
    print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")
    
    # æµ‹è¯•ä¸åŒçš„é‡å è®¾ç½®
    overlap_settings = [0, 20, 50, 80]
    
    for overlap in overlap_settings:
        print(f"\nğŸ”§ é‡å è®¾ç½®: {overlap} å­—ç¬¦")
        
        chunks = sliding_window_split(
            test_text,
            max_tokens=120,
            overlap=overlap,
            by_sentence=True,
            token_counter="character"
        )
        
        print(f"   ğŸ“Š ç»“æœ: {len(chunks)} ä¸ªchunks")
        
        # åˆ†æé‡å å†…å®¹
        for i, chunk in enumerate(chunks, 1):
            print(f"   Chunk {i} ({len(chunk)}å­—ç¬¦): {chunk[:60]}...")
            
            # æ£€æŸ¥ä¸å‰ä¸€ä¸ªchunkçš„é‡å 
            if i > 1:
                prev_chunk = chunks[i-2]  # chunksæ˜¯0-indexed
                
                # ç®€å•çš„é‡å æ£€æµ‹ - æŸ¥æ‰¾å…±åŒçš„å­å­—ç¬¦ä¸²
                overlap_found = False
                for start in range(len(prev_chunk)):
                    for end in range(start + 10, len(prev_chunk) + 1):  # è‡³å°‘10å­—ç¬¦çš„é‡å 
                        substring = prev_chunk[start:end]
                        if substring in chunk:
                            print(f"      ğŸ”„ å‘ç°é‡å : {substring[:30]}...")
                            overlap_found = True
                            break
                    if overlap_found:
                        break
                
                if not overlap_found:
                    print(f"      âš ï¸ æœªå‘ç°æ˜æ˜¾é‡å ")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ é«˜çº§åˆ†å—ç­–ç•¥ç¤ºä¾‹")
    print("=" * 80)
    print("æœ¬ç¤ºä¾‹æ¼”ç¤ºContract Splitterçš„é«˜çº§åŠŸèƒ½å’Œè‡ªå®šä¹‰åˆ†å—ç­–ç•¥")
    
    # æ¼”ç¤ºå„ç§é«˜çº§åˆ†å—åŠŸèƒ½
    demo_sentence_priority_vs_strict_chunking()
    demo_hierarchical_strategies()
    demo_custom_chunking_parameters()
    demo_token_counting_methods()
    demo_overlap_analysis()
    
    print(f"\nğŸ‰ é«˜çº§åˆ†å—ç­–ç•¥ç¤ºä¾‹å®Œæˆ")
    print("=" * 80)
    print("ğŸ’¡ é«˜çº§åˆ†å—æœ€ä½³å®è·µ:")
    print("1. ä¼˜å…ˆä½¿ç”¨å¥å­å®Œæ•´æ€§åˆ†å—ï¼Œé¿å…è¯­ä¹‰ç ´å")
    print("2. æ ¹æ®æ–‡æ¡£ç±»å‹é€‰æ‹©åˆé€‚çš„å±‚æ¬¡åŒ–ç­–ç•¥")
    print("3. è°ƒæ•´max_chunk_sizeå’Œoverlap_ratioä»¥è·å¾—æœ€ä½³æ•ˆæœ")
    print("4. å¯¹äºä¸­æ–‡æ–‡æ¡£ï¼Œcharacterè®¡æ•°é€šå¸¸æ¯”tiktokenæ›´ç›´è§‚")
    print("5. é€‚å½“çš„é‡å å¯ä»¥ä¿æŒä¸Šä¸‹æ–‡è¿ç»­æ€§")
    print("6. æ³•å¾‹æ–‡æ¡£å»ºè®®ä½¿ç”¨è¾ƒå¤§çš„chunk_sizeä»¥ä¿æŒæ¡æ–‡å®Œæ•´æ€§")


if __name__ == "__main__":
    main()
