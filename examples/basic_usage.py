#!/usr/bin/env python3
"""
Contract Splitter åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºä¸‰å¤§æ ¸å¿ƒæ¥å£çš„åŸºæœ¬ç”¨æ³•
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

def demo_hierarchical_chunking():
    """æ¼”ç¤ºæ¥å£1: å±‚æ¬¡åŒ–åˆ†å—æ¥å£"""
    print("ğŸ¯ æ¥å£1: å±‚æ¬¡åŒ–åˆ†å—æ¥å£")
    print("=" * 60)
    
    from contract_splitter import split_document, flatten_sections
    
    # ç¤ºä¾‹æ–‡æ¡£è·¯å¾„ï¼ˆè¯·æ›¿æ¢ä¸ºå®é™…æ–‡æ¡£è·¯å¾„ï¼‰
    document_path = "output/law/é™„ä»¶1.å…³äºä¿®æ”¹ã€Šè¯åˆ¸å…¬å¸åˆ†ç±»ç›‘ç®¡è§„å®šã€‹çš„å†³å®š.pdf"
    
    if not Path(document_path).exists():
        print(f"âš ï¸ ç¤ºä¾‹æ–‡æ¡£ä¸å­˜åœ¨: {document_path}")
        print("è¯·å°†æ‚¨çš„æ–‡æ¡£æ”¾åœ¨è¯¥è·¯å¾„ï¼Œæˆ–ä¿®æ”¹document_pathå˜é‡")
        return
    
    try:
        print(f"ğŸ“„ å¤„ç†æ–‡æ¡£: {Path(document_path).name}")
        
        # 1. å±‚æ¬¡åŒ–åˆ†å—
        print("\nğŸ” æ­¥éª¤1: å±‚æ¬¡åŒ–åˆ†å—")
        sections = split_document(document_path, max_tokens=1000)
        
        print(f"âœ… åˆ†å—å®Œæˆ: {len(sections)} ä¸ªå±‚æ¬¡åŒ–sections")
        
        # æ˜¾ç¤ºå±‚æ¬¡ç»“æ„
        print("\nğŸ“Š æ–‡æ¡£å±‚æ¬¡ç»“æ„:")
        for i, section in enumerate(sections[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
            level = getattr(section, 'level', 0)
            title = getattr(section, 'title', 'Unknown')
            content_preview = section.content[:50] + "..." if len(section.content) > 50 else section.content
            print(f"  {i}. Level {level}: {title}")
            print(f"     å†…å®¹: {content_preview}")
        
        if len(sections) > 5:
            print(f"     ... è¿˜æœ‰ {len(sections) - 5} ä¸ªsections")
        
        # 2. æ‰å¹³åŒ–å¤„ç† - ä¸åŒç­–ç•¥å¯¹æ¯”
        print(f"\nğŸ”§ æ­¥éª¤2: æ‰å¹³åŒ–å¤„ç†")
        
        strategies = [
            ("finest_granularity", "æœ€ç»†ç²’åº¦ - è·å–æœ€å°çš„æ–‡æ¡£å•å…ƒ"),
            ("all_levels", "æ‰€æœ‰å±‚çº§ - åŒ…å«å„å±‚çº§çš„å®Œæ•´å†…å®¹"),
            ("parent_only", "ä»…çˆ¶çº§ - åªä¿ç•™é¡¶çº§sections")
        ]
        
        for strategy, description in strategies:
            print(f"\nğŸ“‹ ç­–ç•¥: {strategy} ({description})")
            chunks = flatten_sections(sections, strategy=strategy)
            print(f"   ç»“æœ: {len(chunks)} ä¸ªchunks")
            
            # æ˜¾ç¤ºå‰2ä¸ªchunksçš„ç¤ºä¾‹
            for i, chunk in enumerate(chunks[:2], 1):
                level = getattr(chunk, 'level', 0)
                content_preview = chunk.content[:80] + "..." if len(chunk.content) > 80 else chunk.content
                print(f"   Chunk {i} (Level {level}): {content_preview}")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")


def demo_sentence_integrity_chunking():
    """æ¼”ç¤ºæ¥å£2: å¥å­å®Œæ•´æ€§åˆ†å—æ¥å£"""
    print("\n\nğŸ¯ æ¥å£2: å¥å­å®Œæ•´æ€§åˆ†å—æ¥å£")
    print("=" * 60)
    
    from contract_splitter import simple_chunk_file
    
    # ç¤ºä¾‹æ–‡æ¡£è·¯å¾„
    document_path = "output/law/é™„ä»¶1.æœŸè´§å…¬å¸äº’è”ç½‘è¥é”€ç®¡ç†æš‚è¡Œè§„å®š.pdf"
    
    if not Path(document_path).exists():
        print(f"âš ï¸ ç¤ºä¾‹æ–‡æ¡£ä¸å­˜åœ¨: {document_path}")
        print("è¯·å°†æ‚¨çš„æ–‡æ¡£æ”¾åœ¨è¯¥è·¯å¾„ï¼Œæˆ–ä¿®æ”¹document_pathå˜é‡")
        return
    
    try:
        print(f"ğŸ“„ å¤„ç†æ–‡æ¡£: {Path(document_path).name}")
        
        # æµ‹è¯•ä¸åŒçš„åˆ†å—å‚æ•°
        test_configs = [
            {"max_chunk_size": 300, "overlap_ratio": 0.1, "name": "å°å— (300å­—ç¬¦, 10%é‡å )"},
            {"max_chunk_size": 600, "overlap_ratio": 0.15, "name": "ä¸­å— (600å­—ç¬¦, 15%é‡å )"},
            {"max_chunk_size": 1000, "overlap_ratio": 0.2, "name": "å¤§å— (1000å­—ç¬¦, 20%é‡å )"},
        ]
        
        for config in test_configs:
            print(f"\nğŸ”§ é…ç½®: {config['name']}")
            
            # å¥å­å®Œæ•´æ€§åˆ†å—
            chunks = simple_chunk_file(
                document_path,
                max_chunk_size=config['max_chunk_size'],
                overlap_ratio=config['overlap_ratio']
            )
            
            # åˆ†æç»“æœ
            chunk_sizes = [len(chunk['content']) for chunk in chunks]
            avg_size = sum(chunk_sizes) / len(chunk_sizes)
            max_size = max(chunk_sizes)
            min_size = min(chunk_sizes)
            
            print(f"   ğŸ“Š ç»“æœ: {len(chunks)} ä¸ªchunks")
            print(f"   ğŸ“ å¤§å°: å¹³å‡{avg_size:.0f}, æœ€å¤§{max_size}, æœ€å°{min_size} å­—ç¬¦")
            
            # æ£€æŸ¥å¥å­å®Œæ•´æ€§
            complete_sentences = 0
            for chunk in chunks:
                content = chunk['content'].strip()
                if content.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', '.', '!', '?', ';')):
                    complete_sentences += 1
            
            completion_rate = complete_sentences / len(chunks) * 100
            print(f"   âœ… å¥å­å®Œæ•´ç‡: {completion_rate:.1f}% ({complete_sentences}/{len(chunks)})")
            
            # æ˜¾ç¤ºå‰2ä¸ªchunksç¤ºä¾‹
            print(f"   ğŸ“ ç¤ºä¾‹chunks:")
            for i, chunk in enumerate(chunks[:2], 1):
                content_preview = chunk['content'][:100] + "..." if len(chunk['content']) > 100 else chunk['content']
                print(f"      Chunk {i}: {content_preview}")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")


def demo_text_extraction():
    """æ¼”ç¤ºæ¥å£3: å¤šæ ¼å¼æ–‡æœ¬æå–æ¥å£"""
    print("\n\nğŸ¯ æ¥å£3: å¤šæ ¼å¼æ–‡æœ¬æå–æ¥å£")
    print("=" * 60)
    
    from contract_splitter import SplitterFactory
    import os
    
    # æµ‹è¯•ä¸åŒæ ¼å¼çš„æ–‡æ¡£
    test_files = [
        ("output/law/é™„ä»¶1.å…³äºä¿®æ”¹ã€Šè¯åˆ¸å…¬å¸åˆ†ç±»ç›‘ç®¡è§„å®šã€‹çš„å†³å®š.pdf", "PDFæ–‡æ¡£"),
        ("output/law/9147de404f6d4df986b0cb41acd47aac.wps", "WPSæ–‡æ¡£"),
        # å¯ä»¥æ·»åŠ æ›´å¤šæ ¼å¼çš„æµ‹è¯•æ–‡ä»¶
    ]
    
    factory = SplitterFactory()
    
    for file_path, file_type in test_files:
        if not os.path.exists(file_path):
            print(f"âš ï¸ {file_type}ä¸å­˜åœ¨: {file_path}")
            continue
        
        try:
            print(f"\nğŸ“„ å¤„ç†{file_type}: {Path(file_path).name}")
            
            # 1. è‡ªåŠ¨æ ¼å¼æ£€æµ‹
            file_format = factory.detect_file_format(file_path)
            print(f"   ğŸ” æ£€æµ‹æ ¼å¼: .{file_format}")
            
            # 2. åˆ›å»ºåˆé€‚çš„åˆ†å‰²å™¨
            splitter = factory.create_splitter(file_path)
            print(f"   ğŸ­ ä½¿ç”¨åˆ†å‰²å™¨: {type(splitter).__name__}")
            
            # 3. æå–æ–‡æœ¬å†…å®¹
            sections = splitter.split(file_path)
            
            # 4. åˆå¹¶ä¸ºå®Œæ•´æ–‡æœ¬
            full_text = "\n".join([section.content for section in sections])
            
            # 5. åˆ†ææå–ç»“æœ
            print(f"   ğŸ“Š æå–ç»“æœ:")
            print(f"      - Sectionsæ•°é‡: {len(sections)}")
            print(f"      - æ€»æ–‡æœ¬é•¿åº¦: {len(full_text)} å­—ç¬¦")
            print(f"      - å¹³å‡sectioné•¿åº¦: {len(full_text) / len(sections):.0f} å­—ç¬¦")
            
            # 6. æ˜¾ç¤ºæ–‡æœ¬é¢„è§ˆ
            print(f"   ğŸ“ æ–‡æœ¬é¢„è§ˆ:")
            preview_text = full_text[:200] + "..." if len(full_text) > 200 else full_text
            print(f"      {preview_text}")
            
            # 7. æ£€æŸ¥æ–‡æœ¬è´¨é‡
            chinese_chars = sum(1 for char in full_text if '\u4e00' <= char <= '\u9fff')
            chinese_ratio = chinese_chars / len(full_text) * 100 if full_text else 0
            print(f"   ğŸ‡¨ğŸ‡³ ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹: {chinese_ratio:.1f}%")
            
        except Exception as e:
            print(f"   âŒ å¤„ç†å¤±è´¥: {str(e)}")


def demo_advanced_usage():
    """æ¼”ç¤ºé«˜çº§ç”¨æ³•"""
    print("\n\nğŸ¯ é«˜çº§ç”¨æ³•ç¤ºä¾‹")
    print("=" * 60)
    
    # 1. æ³•å¾‹æ–‡æ¡£ä¸“ä¸šå¤„ç†
    print("ğŸ“š æ³•å¾‹æ–‡æ¡£ä¸“ä¸šå¤„ç†:")
    try:
        from contract_splitter.domain_helpers import split_legal_document
        
        legal_doc = "output/law/é™„ä»¶1.å…³äºä¿®æ”¹ã€Šè¯åˆ¸å…¬å¸åˆ†ç±»ç›‘ç®¡è§„å®šã€‹çš„å†³å®š.pdf"
        if Path(legal_doc).exists():
            chunks = split_legal_document(legal_doc, max_tokens=800)
            print(f"   âœ… æ³•å¾‹æ–‡æ¡£åˆ†å—: {len(chunks)} ä¸ªæ¡æ–‡å—")
            
            # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ¡æ–‡å—
            if chunks:
                first_chunk = chunks[0][:150] + "..." if len(chunks[0]) > 150 else chunks[0]
                print(f"   ğŸ“ ç¬¬ä¸€ä¸ªæ¡æ–‡å—: {first_chunk}")
        else:
            print(f"   âš ï¸ æ³•å¾‹æ–‡æ¡£ä¸å­˜åœ¨: {legal_doc}")
    except Exception as e:
        print(f"   âŒ æ³•å¾‹æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}")
    
    # 2. è‡ªå®šä¹‰åˆ†å—ç­–ç•¥
    print(f"\nğŸ”§ è‡ªå®šä¹‰åˆ†å—ç­–ç•¥:")
    try:
        from contract_splitter.utils import sliding_window_split
        
        sample_text = "ç¬¬ä¸€æ¡ è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ¡æ–‡ã€‚ç¬¬äºŒæ¡ è¿™æ˜¯å¦ä¸€ä¸ªæµ‹è¯•æ¡æ–‡ã€‚ç¬¬ä¸‰æ¡ è¿™æ˜¯ç¬¬ä¸‰ä¸ªæµ‹è¯•æ¡æ–‡ï¼Œå†…å®¹ç¨å¾®é•¿ä¸€äº›ã€‚"
        
        # å¥å­ä¼˜å…ˆåˆ†å—
        chunks = sliding_window_split(
            sample_text,
            max_tokens=50,
            overlap=10,
            by_sentence=True,
            token_counter="character"
        )
        
        print(f"   âœ… è‡ªå®šä¹‰åˆ†å—: {len(chunks)} ä¸ªchunks")
        for i, chunk in enumerate(chunks, 1):
            print(f"   Chunk {i} ({len(chunk)}å­—ç¬¦): {chunk}")
            
    except Exception as e:
        print(f"   âŒ è‡ªå®šä¹‰åˆ†å—å¤±è´¥: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Contract Splitter åŸºç¡€ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 80)
    print("æœ¬ç¤ºä¾‹æ¼”ç¤ºä¸‰å¤§æ ¸å¿ƒæ¥å£çš„åŸºæœ¬ç”¨æ³•")
    print("è¯·ç¡®ä¿åœ¨output/lawç›®å½•ä¸‹æœ‰æµ‹è¯•æ–‡æ¡£")
    
    # æ¼”ç¤ºä¸‰å¤§æ ¸å¿ƒæ¥å£
    demo_hierarchical_chunking()
    demo_sentence_integrity_chunking()
    demo_text_extraction()
    demo_advanced_usage()
    
    print(f"\nğŸ‰ ç¤ºä¾‹æ¼”ç¤ºå®Œæˆ")
    print("=" * 80)
    print("ğŸ’¡ æç¤º:")
    print("1. æ ¹æ®æ–‡æ¡£ç±»å‹é€‰æ‹©åˆé€‚çš„åˆ†å—ç­–ç•¥")
    print("2. è°ƒæ•´å‚æ•°ä»¥è·å¾—æœ€ä½³åˆ†å—æ•ˆæœ")
    print("3. æ³•å¾‹æ–‡æ¡£å»ºè®®ä½¿ç”¨ä¸“ä¸šçš„æ³•å¾‹åˆ†å—æ¥å£")
    print("4. æŸ¥çœ‹examplesç›®å½•è·å–æ›´å¤šä¸“ä¸šç¤ºä¾‹")


if __name__ == "__main__":
    main()
